{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(stringr)\n",
    "library(RCurl)\n",
    "##HOUSE VOTES DATASET####\n",
    "votesfile <- getURL(\"http://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data)\n",
    "votesdata <- read.table(text=votesfile)\n",
    "votesdata$V1 <- as.character(votesdata$V1)\n",
    "splitdat = do.call(\"rbind\",strsplit(votesdata$V1,\",\"))\n",
    "splitdat[splitdat == \"?\"] = NA #convert \"?\" to NA\n",
    "splitdat = as.data.frame(splitdat)\n",
    "#splitdat = data.frame(apply(splitdat,2,factor))\n",
    "str(splitdat)\n",
    "splitdat = splitdat[complete.cases(splitdat),]\n",
    "##IRIS DATASET####\n",
    "irisfile <- getURL(\"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\")\n",
    "Iris <- read.csv(text = irisfile)\n",
    "colnames(Iris) <- c(\"sepal.length\",\"sepal.width\",\"petal.length\",\"petal.width\",\"class\")\n",
    "#str(Iris)\n",
    "Iris.features <- Iris\n",
    "Iris.features$Iris.setosa <- NULL\n",
    "#View(Iris.features)\n",
    "###Determine number of clusters#####\n",
    "#install.packages(\"factoextra\")\n",
    "#if(!require(devtools)) install.packages(\"devtools\")\n",
    "#devtools::install_github(\"kassambara/factoextra\")\n",
    "#pkgs <- c(\"cluster\",  \"NbClust\")\n",
    "#install.packages(pkgs)\n",
    "library(factoextra)\n",
    "library(cluster)\n",
    "library(NbClust)\n",
    "A <- model.matrix(V1~.,splitdat)\n",
    "A <- as.data.frame(A)\n",
    "A <- A[complete.cases(A),]\n",
    "data <- A\n",
    "#head(A)\n",
    "data <- A\n",
    "#head(data)\n",
    "data3 <- data\n",
    "data3$`(Intercept)` <- NULL\n",
    "data4 <- data3\n",
    "data4 <- scale(data4) #scale house votes for kmeans++\n",
    "#scale data\n",
    "iris.scaled <- scale(Iris[,-5])\n",
    "#head(iris.scaled)\n",
    "\n",
    "##K-MEANS++####\n",
    "kmeansp2 <- function(x, k, iter.max = 10, nstart = 1, ...) {\n",
    "  n <- nrow(x) # number of data points\n",
    "  centers <- numeric(k) # IDs of centers\n",
    "  distances <- matrix(numeric(n * (k - 1)), ncol = k - 1) # distances[i, j]: The distance between x[i,] and x[centers[j],]\n",
    "  res.best <- list(tot.withinss = Inf) # the best result among <nstart> iterations\n",
    "  for (rep in 1:nstart) {\n",
    "    pr <- rep(1, n) # probability for sampling centers\n",
    "    for (i in 1:(k - 1)) {\n",
    "      centers[i] <- sample.int(n, 1, prob = pr) # Pick up the ith center\n",
    "      distances[, i] <- colSums((t(x) - x[centers[i], ])^2) # Compute (the square of) distances to the center\n",
    "      pr <- distances[cbind(1:n, max.col(-distances[, 1:i, drop = FALSE]))] # Compute probaiblity for the next sampling\n",
    "    }\n",
    "    centers[k] <- sample.int(n, 1, prob = pr)\n",
    "    ## Perform k-means with the obtained centers\n",
    "    res <- kmeans(x, x[centers, ], iter.max = iter.max, nstart = 1, ...)\n",
    "    res$inicial.centers <- x[centers, ]\n",
    "    ## Store the best result\n",
    "    if (res$tot.withinss < res.best$tot.withinss) {\n",
    "      res.best <- res\n",
    "    }\n",
    "  }\n",
    "  res.best\n",
    "}\n",
    "\n",
    "##IRIS K++####\n",
    "iris.kmeansp2 <- kmeansp2(iris.scaled,k=3)\n",
    "tab_kmeanssp2 <- table(iris.kmeansp2$cluster,Iris$class)\n",
    "#tab_kmeanssp2\n",
    "acc_iris <- sum(tab_kmeansp2[1,1],tab_kmeansp2[2,2],tab_kmeansp2[3,3])/sum(tab_kmeansp2)\n",
    "print(c(\"Accuracy IRIS K-means++: \",acc_iris))\n",
    "##HOUSE VOTES K++####\n",
    "hv.kmeansp2 <- kmeansp2(data4,k=2)\n",
    "tab_kmeansp2.hv <- table(hv.kmeansp2$cluster,splitdat$V1)\n",
    "#tab_kmeansp2.hv\n",
    "acc_hv <- sum(tab_kmeansp2.hv[1,1],tab_kmeansp2.hv[2,2])/sum(tab_kmeansp2.hv)\n",
    "print(c(\"Accuracy HOUSE VOTES K-means++: \",acc_hv))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Elbow method IRIS K-Means####\n",
    "set.seed(123)\n",
    "#Compute and plot wss for k = 2 to k = 15\n",
    "k.max <- 15 # Maximal number of clusters\n",
    "data.scaled <- iris.scaled\n",
    "wss <- sapply(1:k.max, \n",
    "              function(k){kmeans(data.scaled, k, nstart=10 )$tot.withinss})\n",
    "plot(1:k.max, wss,\n",
    "     type=\"b\", pch = 19, frame = FALSE, \n",
    "     xlab=\"Number of clusters K\",\n",
    "     ylab=\"Total within-clusters sum of squares\", main = \"Elbow Plot IRIS\")\n",
    "#Elbow line indicating 3 is a good cluster number\n",
    "abline(v = 3, lty =2)\n",
    "\n",
    "##Elbow method HOUSE VOTES K-Means####\n",
    "#created dummy variables for categorical predictors\n",
    "A <- model.matrix(V1~.,splitdat)\n",
    "A <- as.data.frame(A)\n",
    "A <- A[complete.cases(A),]\n",
    "data <- A\n",
    "wss <- sapply(1:k.max, \n",
    "              function(k){kmeans(data, k, nstart=10 )$tot.withinss})\n",
    "plot(1:k.max, wss,\n",
    "     type=\"b\", pch = 19, frame = FALSE, \n",
    "     xlab=\"Number of clusters K\",\n",
    "     ylab=\"Total within-clusters sum of squares\",main = \"Elbow Plot HOUSE VOTES\")\n",
    "#Elbow line indicating 2 is a good cluster number\n",
    "abline(v = 2, lty =2)\n",
    "\n",
    "##K-MEANS IRIS#######\n",
    "\n",
    "#k = 3 from Elbow method above\n",
    "Iris.features$class <- NULL\n",
    "results <- kmeans(Iris.features, 3)\n",
    "#results\n",
    "tab_iris_kmeans <- table(Iris$class,results$cluster)\n",
    "acc_iris_km <- sum(tab_iris_kmeans[1,1],tab_iris_kmeans[2,2],tab_iris_kmeans[3,3])/sum(tab_iris_kmeans)\n",
    "print(c(\"Accuracy Iris K-Means: \",acc_iris_km))\n",
    "#str(Iris)\n",
    "#Sepal length and width cluster\n",
    "plot(Iris[c(\"sepal.length\",\"sepal.width\")],col=results$cluster,main = \"Predicted\")\n",
    "plot(Iris[c(\"sepal.length\",\"sepal.width\")],col = Iris$class,main = \"Actual\")\n",
    "#Petal length and width cluster\n",
    "plot(Iris[c(\"petal.length\",\"petal.width\")],col=results$cluster,main = \"Predicted\")\n",
    "plot(Iris[c(\"petal.length\",\"petal.width\")],col=Iris$class,main = \"Actual\")\n",
    "\n",
    "##K-MEANS HOUSE VOTES#######\n",
    "head(splitdat)\n",
    "#created dummy variables for categorical predictors\n",
    "A <- model.matrix(V1~.,splitdat)\n",
    "head(A)\n",
    "#k = 2 from Elbow method above\n",
    "res_hv <- kmeans(A,2)\n",
    "#res_hv\n",
    "tab_hv_kmeans <- table(splitdat$V1,res_hv$cluster)\n",
    "#tab_hv_kmeans\n",
    "acc_hv_kmeans <- sum(tab_hv_kmeans[1,1],tab_hv_kmeans[2,2])/sum(tab_hv_kmeans)\n",
    "print(c(\"Accuracy House Votes K-Means: \",acc_hv_kmeans))\n",
    "#plot(splitdat[c(\"V2\",\"V3\")],col=res_hv$cluster,main = \"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##MIXTURE MODELS IRIS####\n",
    "library(mclust)\n",
    "#xyclust <- Mclust(Iris.features) #Just two clusters with BIC, not a good choice\n",
    "xyclust <- Mclust(Iris.features,G=3)\n",
    "#plot(xyclust)\n",
    "#summary(xyclust)\n",
    "#xyclust$classification\n",
    "tab_mclust_iris <- table(Iris$class,xyclust$classification)\n",
    "acc_iris_mm <- sum(tab_mclust_iris[1,1],tab_mclust_iris[2,2],tab_mclust_iris[3,3])/sum(tab_mclust_iris)\n",
    "print(c(\"Accuracy Iris Mixture Models: \",acc_iris_mm))\n",
    "\n",
    "##MIXTURE MODELS HOUSE VOTES####\n",
    "head(A)\n",
    "data <- A\n",
    "data <- as.data.frame(data)\n",
    "data$`(Intercept)` <- NULL\n",
    "#xyclust.hv <- Mclust(data)# Considers 5 clusters, not a good choice\n",
    "xyclust.hv <- Mclust(data,G=2)\n",
    "#plot(xyclust.hv)\n",
    "tab_mclust_hv <- table(xyclust.hv$classification,splitdat$V1)\n",
    "acc_hv_mm <- sum(tab_mclust_hv[1,1],tab_mclust_hv[2,2])/sum(tab_mclust_hv)\n",
    "print(c(\"Accuracy House Votes Mixture Models: \",acc_hv_mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##HIERARCHICAL CLUSTERING IRIS####\n",
    "fn <- fviz_nbclust(iris.scaled,pam,method = \"wss\")\n",
    "#fn\n",
    "#we can see an elbow at k = 3, k=2 could also be considered but the slope is steeper for 2-3 than 3-15 so we choose 3 as elbow point\n",
    "fn+geom_vline(xintercept = 3, linetype = 2)\n",
    "dist.iris <- dist(as.matrix(Iris))\n",
    "hc <- hclust(dist.iris)\n",
    "clustCut <- cutree(hc,3)\n",
    "tab_iris_clust <- table(clustCut,Iris$class)\n",
    "#tab_iris_clust\n",
    "acc_iris_hc <- sum(tab_iris_clust[1,1],tab_iris_clust[2,2],tab_iris_clust[3,3])/sum(tab_iris_clust)\n",
    "#plot(hc)\n",
    "print(c(\"Accuracy Iris Hierarchical Cluster:\",acc_iris_hc))\n",
    "\n",
    "##HIERARCHICAL CLUSTERING HOUSE VOTES#####\n",
    "fn2 <- fviz_nbclust(data,pam,method = \"wss\")\n",
    "#fn2\n",
    "#we can see a clear elbow at k = 2\n",
    "fn2+geom_vline(xintercept = 2, linetype = 2)\n",
    "dist.hv <- dist(as.matrix(A))\n",
    "hc.hv <- hclust(dist.hv)\n",
    "#plot(hc.hv)\n",
    "clustCut.hv <- cutree(hc.hv,2)\n",
    "tab_hv_clust <- table(clustCut.hv,splitdat$V1)\n",
    "#tab_hv_clust\n",
    "acc_hv_hc <- sum(tab_hv_clust[1,1],tab_hv_clust[2,2])/sum(tab_hv_clust)\n",
    "print(c(\"Accuracy House Votes Hierarchical Cluster: \",acc_hv_hc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##VISUALIZATION PCA-IRIS####\n",
    "log.ir <- log(Iris[,1:4])\n",
    "ir.species <- Iris[,5]\n",
    "#Apply PCA, scaled\n",
    "ir.pca <- prcomp(log.ir,center = TRUE,scale. = TRUE)\n",
    "#ir.pca\n",
    "plot(ir.pca,type=\"l\")\n",
    "library(devtools)\n",
    "#install_github(\"ggbiplot\", \"vqv\")\n",
    "library(ggbiplot)\n",
    "g <- ggbiplot(ir.pca, obs.scale = 1, var.scale = 1, \n",
    "              groups = ir.species, ellipse = TRUE, \n",
    "              circle = TRUE)\n",
    "g <- g + scale_color_discrete(name = '')\n",
    "g <- g + theme(legend.direction = 'horizontal', \n",
    "               legend.position = 'top')\n",
    "print(g)\n",
    "\n",
    "##VISUALIZATION PCA-HOUSE VOTES####\n",
    "data3 <- data\n",
    "data3$`(Intercept)` <- NULL\n",
    "hv.class <- splitdat$V1\n",
    "hv.pca <- prcomp(data3,center = TRUE)\n",
    "hv.pca\n",
    "plot(hv.pca,type=\"l\")\n",
    "g2 <- ggbiplot(hv.pca,groups=hv.class,ellipse = TRUE, \n",
    "               circle = TRUE)\n",
    "g2 <- g2 + scale_color_discrete(name = '')\n",
    "g2 <- g2 + theme(legend.direction = 'horizontal', \n",
    "               legend.position = 'top')\n",
    "print(g2)\n",
    "\n",
    "##VISUALIZATION IRIS AUTOENCODER####\n",
    "#install.packages(\"h2o\")\n",
    "library(h2o)\n",
    "h2o.init()\n",
    "head(Iris)\n",
    "str(Iris)\n",
    "iris.hex <- as.h2o(Iris)\n",
    "iris.dl <- h2o.deeplearning(x=1:4,y=5,training_frame=iris.hex,hidden=c(10,5,10))\n",
    "#extract features from middle layers\n",
    "#layer 2\n",
    "mid.features <- h2o.deepfeatures(iris.dl,iris.hex,layer = 2)\n",
    "plotdata <- as.data.frame(mid.features)\n",
    "plotdata$label <- as.character(as.vector(Iris$class))\n",
    "qplot(plotdata$DF.L2.C1,plotdata$DF.L2.C2,data=plotdata,color=label)\n",
    "#layer 3\n",
    "mid.features3 <- h2o.deepfeatures(iris.dl,iris.hex,layer = 3)\n",
    "plotdata3 <- as.data.frame(mid.features3)\n",
    "plotdata3$label <- as.character(as.vector(Iris$class))\n",
    "qplot(plotdata3$DF.L3.C1,plotdata3$DF.L3.C2,data=plotdata3,color=label,main = \"Hidden layer 3 neural net\")\n",
    "#prediction\n",
    "predictions <- h2o.predict(iris.dl,iris.hex)\n",
    "#predictions\n",
    "\n",
    "\n",
    "##VISUALIZATION House Votes AUTOENCODER####\n",
    "h2o.shutdown()\n",
    "#disabling assertions in H2O\n",
    "h2o.init(nthreads=-1,enable_assertions = FALSE)\n",
    "nrow(A)\n",
    "nrow(splitdat)\n",
    "nrow(data)\n",
    "data <- as.data.frame(scale(A))\n",
    "head(data)\n",
    "data$V1 <- as.character(as.vector(splitdat$V1))\n",
    "data$V1 <- as.factor(data$V1)\n",
    "head(data)\n",
    "data2 <- data\n",
    "data2$`(Intercept)`<- NULL\n",
    "head(data2)\n",
    "hv.hex <- as.h2o(data2)\n",
    "hv.dl <- h2o.deeplearning(x=1:16,y=17,training_frame=hv.hex,hidden=c(20,10,2,10,20))\n",
    "hv.features <- h2o.deepfeatures(hv.dl,hv.hex,layer=3)\n",
    "plotdata3.hv <- as.data.frame(hv.features)\n",
    "plotdata3.hv$label <- as.character(as.vector(splitdat$V1))\n",
    "qplot(plotdata3.hv$DF.L3.C1,plotdata3.hv$DF.L3.C2,data=plotdata3.hv,color=label,main=\"Hidden layer 3 Neural Net\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
