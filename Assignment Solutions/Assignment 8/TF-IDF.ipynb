{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "install.packages(\"text2vec\")\n",
    "library(text2vec)\n",
    "library(data.table)\n",
    "library(glmnet)\n",
    "rm(list = ls())\n",
    "library(plyr)\n",
    "library(ggplot2)\n",
    "library(tm)\n",
    "library(lsa)\n",
    "datacsv = read.csv(\"train_talk.csv\")\n",
    "datacsv <- as.data.frame(datacsv)\n",
    "datacsv <- datacsv[,1:3]\n",
    "datacsv <- na.omit(datacsv)\n",
    "setDT(datacsv)\n",
    "set.seed(2016L)\n",
    "all_ids <- c(1:nrow(datacsv))\n",
    "datacsv$id <- all_ids\n",
    "train_ids <- sample(all_ids,0.8*nrow(datacsv))\n",
    "test_ids <- setdiff(all_ids,train_ids)\n",
    "train <- datacsv[datacsv$id%in%train_ids,]\n",
    "nrow(train)\n",
    "test <- datacsv[datacsv$id%in%test_ids,]\n",
    "nrow(test)\n",
    "prep_fun = tolower\n",
    "tok_fun = word_tokenizer\n",
    "train$detail <- as.character(train$detail)\n",
    "train$title <- as.character(train$title)\n",
    "test$detail <- as.character(test$detail)\n",
    "test$title <- as.character(test$title)\n",
    "it_train = itoken(train$detail,\n",
    "                  preprocessor = prep_fun,\n",
    "                  tokenizer = tok_fun,\n",
    "                  ids = train$id,\n",
    "                  progressbar = FALSE)\n",
    "it_test = test$detail %>% \n",
    "  prep_fun %>% \n",
    "  tok_fun %>% \n",
    "  itoken(ids = test$id, \n",
    "         # turn off progressbar because it won't look nice in rmd\n",
    "         progressbar = FALSE)\n",
    "vocab = create_vocabulary(it_train)\n",
    "vectorizer = vocab_vectorizer(vocab)\n",
    "t1 = Sys.time()\n",
    "dtm_train = create_dtm(it_train, vectorizer)\n",
    "print(difftime(Sys.time(), t1, units = 'sec'))\n",
    "# define tfidf model\n",
    "tfidf = TfIdf$new()\n",
    "# fit model to train data and transform train data with fitted model\n",
    "dtm_train_tfidf = fit_transform(dtm_train, tfidf)\n",
    "# tfidf modified by fit_transform() call!\n",
    "# apply pre-trained tf-idf transformation to test data\n",
    "dtm_test_tfidf  = create_dtm(it_test, vectorizer) %>% \n",
    "  transform(tfidf)\n",
    "str(dtm_train_tfidf)\n",
    "str(train)\n",
    "tr2 <- train\n",
    "tr2$title <- as.factor(as.character(tr2$title))\n",
    "unique(tr2$title)\n",
    "str(tr2)\n",
    "glmnet_classifier = cv.glmnet(x = dtm_train_tfidf, y = train[['title']], \n",
    "                              family = 'binomial', \n",
    "                              alpha = 1,\n",
    "                              type.measure = \"auc\",\n",
    "                              nfolds = NFOLDS,\n",
    "                              thresh = 1e-3,\n",
    "                              maxit = 1e3)\n",
    "\n",
    "#-----------#####\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
